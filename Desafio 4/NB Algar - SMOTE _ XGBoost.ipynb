{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "#  Desafio Algar\n\nPrimeiro vamos instalar as bibliotecas para que possamos ustilizar o scikit-learn, SMOTE e XGBoostClassifier."}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "#!pip install scikit-learn --upgrade\n#!pip install numpy  --upgrade\n#!pip install pandas --upgrade\n#!pip install imbalanced-learn --upgrade\n!pip install imbalanced-learn==0.4.3 --upgrade\n!pip install scikit-learn==0.20.0 --upgrade", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Collecting imbalanced-learn==0.4.3\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/4c/7557e1c2e791bd43878f8c82065bddc5798252084f26ef44527c02262af1/imbalanced_learn-0.4.3-py3-none-any.whl (166kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 174kB 8.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from imbalanced-learn==0.4.3) (0.20.3)\nRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from imbalanced-learn==0.4.3) (1.2.0)\nRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from imbalanced-learn==0.4.3) (1.15.4)\nInstalling collected packages: imbalanced-learn\nSuccessfully installed imbalanced-learn-0.4.3\nCollecting scikit-learn==0.20.1\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/26/d04320c3edf2d59b1fcd0720b46753d4d603a76e68d8ad10a9b92ab06db2/scikit_learn-0.20.1-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.4MB 10.0MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn==0.20.1) (1.15.4)\nRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn==0.20.1) (1.2.0)\n\u001b[31mERROR: autoai-libs 1.10.5 has requirement numpy>=1.16.4, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n\u001b[31mERROR: autoai-libs 1.10.5 has requirement pandas>=0.24.2, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n\u001b[31mERROR: autoai-libs 1.10.5 has requirement scikit-learn==0.20.3, but you'll have scikit-learn 0.20.1 which is incompatible.\u001b[0m\nInstalling collected packages: scikit-learn\n  Found existing installation: scikit-learn 0.20.3\n    Uninstalling scikit-learn-0.20.3:\n      Successfully uninstalled scikit-learn-0.20.3\nSuccessfully installed scikit-learn-0.20.1\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import pandas               as pd\nfrom sklearn.model_selection  import train_test_split, GridSearchCV,\\\n                                     StratifiedKFold\nfrom sklearn.preprocessing    import OneHotEncoder\nfrom sklearn.metrics          import balanced_accuracy_score,\\\n                                     confusion_matrix, roc_auc_score\n# Import xgboost\nimport xgboost              as xgb\n\nfrom imblearn.over_sampling   import SMOTE\nfrom imblearn.under_sampling  import RandomUnderSampler\nfrom imblearn.pipeline        import Pipeline", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Vamos ler o arquivo de dados fornecido com o desafio"}, {"metadata": {}, "cell_type": "code", "source": "# L\u00ea o arquivo de dados\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_c7e6595abc744e069b18b5eacdb9a257 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='Z0WJnLqVWIhHc3pyswXI4LarKckCi0Ue2TmkUm9-kqrL',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_c7e6595abc744e069b18b5eacdb9a257.get_object(Bucket='mbtcdesafio4algar-donotdelete-pr-isjfn8wys52owr',Key='algar-dataset-treino.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\n\nprint(df.info(), '\\n')\nprint('Tipo de Campos e quantidade de colunas\\n', df.dtypes.value_counts())", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1370 entries, 0 to 1369\nData columns (total 35 columns):\nIdade                                         1370 non-null int64\nLocal de trabalho                             1370 non-null object\nPontua\u00e7\u00e3o teste                               1370 non-null int64\nDepartmento                                   1370 non-null object\nDistancia casa-trabalho                       1370 non-null int64\nEducacao                                      1370 non-null object\nArea                                          1370 non-null object\nPossui carro                                  1370 non-null int64\nSubordinado                                   1370 non-null int64\nSatisfa\u00e7\u00e3o com o ambiente no emprego atual    1370 non-null int64\nGenero                                        1370 non-null object\nHoras voluntariado                            1370 non-null int64\nEnvolvimento com trabalho                     1370 non-null int64\nPosicao                                       1370 non-null int64\nCargo                                         1370 non-null object\nSatisfa\u00e7\u00e3o com emprego                        1370 non-null int64\nEstado civil                                  1370 non-null object\nRenda                                         1370 non-null int64\nBonus de performance                          1370 non-null int64\nQuantidade de empresas que trabalho           1370 non-null int64\nMaior de idade                                1370 non-null int64\nNecessita de hora extra                       1370 non-null object\nAumento de salario%                           1370 non-null int64\nPerformance na entrevista                     1370 non-null int64\nSatisfa\u00e7\u00e3o com a rela\u00e7\u00e3o                      1370 non-null int64\nHoras de trabalho padr\u00e3o                      1370 non-null int64\nBeneficios                                    1370 non-null int64\nAnos de experiencia                           1370 non-null int64\nHoras de treinamento ultimo ano               1370 non-null int64\nEstilo de vida                                1370 non-null int64\nAnos na \u00faltima empresa                        1370 non-null int64\nAnos na posi\u00e7\u00e3o atual                         1370 non-null int64\nAnos desde \u00faltima promo\u00e7\u00e3o                    1370 non-null int64\nAnos com a mesma ger\u00eancia                     1370 non-null int64\nContratar                                     1370 non-null object\ndtypes: int64(26), object(9)\nmemory usage: 374.7+ KB\nNone \n\nTipo de Campos e quantidade de colunas\n int64     26\nobject     9\ndtype: int64\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Notamos que o arquivo \u00e9 composto por colunas dos tipos inteiro e alfanum\u00e9rico."}, {"metadata": {}, "cell_type": "code", "source": "# Columns ith one value\na= [col for col in df.columns if df[col].value_counts().count()<2]\nprint('Columns with unique value:', a)", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "Columns with unique value: ['Possui carro', 'Maior de idade', 'Horas de trabalho padr\u00e3o']\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Subordinado has unique values\nprint(df['Subordinado'].value_counts().count() == len(df['Subordinado']))", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "True\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Get Features and target\nX = df.iloc[:,:-1]\ny = df.iloc[:,-1]\n\n# Eliminate columns with unique feature values\nX = X.drop(a + ['Subordinado'], axis=1)\n\n# Categorical Columns\nc_columns = X.select_dtypes(include='object')\nnc_columns = [col for col in X.columns if col not in c_columns.columns]\n\nohe = OneHotEncoder(handle_unknown='ignore')\n\nc_columns = pd.DataFrame(ohe.fit_transform(c_columns).toarray())\nc_columns.columns = ohe.get_feature_names()\n\nX = pd.concat([X[nc_columns], c_columns], axis=1)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Train test split  75% / 25%\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=555)", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Assemble Model\n\n# Instantiate the XGBClassifier: xg_cl\nxg_cl = xgb.XGBClassifier(objective='binary:logistic', random_state=123)\n\n# tunning parameters\ngbm_param_grid = [\n    {\n     'SMOTE__sampling_strategy': [0.5, 0.4, 0.3],\n     'under__sampling_strategy': [0.5, 0.6, 0.7],\n     'model__colsample_bytree': [0.055],\n     'model__n_estimators': [130, 150, 200],\n     'model__max_depth': [1, 2, 3],\n     'model__reg_alpha': [0, 0.25, 0.3, 0.35],\n     'model__learning_rate': [0.3, 0.35, 0.5, 0.6]\n    }\n]\n# Instantiate the classifier: gbm\ngbm = xgb.XGBClassifier()\nover = SMOTE(sampling_strategy=0.5)\nunder = RandomUnderSampler(sampling_strategy=0.5, random_state=555)\nkfold = StratifiedKFold(n_splits=5, shuffle=False)\n\n# Assamble Pipeline\nsteps = [('SMOTE', over),\n         ('under', under), \n         ('model', gbm)]\n\npipeline = Pipeline(steps=steps)\n\n# Perform grid search: grid_mse\ngrid_acc = GridSearchCV(param_grid=gbm_param_grid, estimator=pipeline,\n                        scoring = \"balanced_accuracy\", cv=kfold, verbose=1,\n                        n_jobs=2)", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Tune Model\n# Fit grid_mse to the data\ngrid_acc.fit(X_train, y_train)", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n", "name": "stdout"}, {"output_type": "stream", "text": "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n", "name": "stderr"}, {"output_type": "error", "ename": "ValueError", "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54'] ['Idade', 'Pontua\u00e7\u00e3o teste', 'Distancia casa-trabalho', 'Satisfa\u00e7\u00e3o com o ambiente no emprego atual', 'Horas voluntariado', 'Envolvimento com trabalho', 'Posicao', 'Satisfa\u00e7\u00e3o com emprego', 'Renda', 'Bonus de performance', 'Quantidade de empresas que trabalho', 'Aumento de salario%', 'Performance na entrevista', 'Satisfa\u00e7\u00e3o com a rela\u00e7\u00e3o', 'Beneficios', 'Anos de experiencia', 'Horas de treinamento ultimo ano', 'Estilo de vida', 'Anos na \u00faltima empresa', 'Anos na posi\u00e7\u00e3o atual', 'Anos desde \u00faltima promo\u00e7\u00e3o', 'Anos com a mesma ger\u00eancia', 'x0_Cliente', 'x0_Escrit\u00f3rio', 'x0_Misto', 'x1_Engenharia', 'x1_RH', 'x1_Vendas', 'x2_M\u00e9dio completo', 'x2_P\u00f3s-gradu\u00e7\u00e3o', 'x2_Superior completo', 'x2_Superior incompleto', 'x2_Superior incompleto - cursando', 'x3_Ci\u00eancias das natureza', 'x3_Ci\u00eancias humanas', 'x3_Faculdade T\u00e9cnica', 'x3_Marketing', 'x3_Medicina', 'x3_Outros', 'x4_F', 'x4_M', 'x5_Analista', 'x5_Assistente', 'x5_Diretor', 'x5_Engenheiro', 'x5_Gerente', 'x5_Supervisor', 'x5_Tecnico', 'x5_Vendedo senior', 'x5_Vendedor junior', 'x6_Casado', 'x6_Divorciado', 'x6_Solteiro', 'x7_N\u00e3o', 'x7_Sim']\nexpected f43, f32, f46, f50, f28, f37, f30, f40, f7, f21, f29, f47, f9, f8, f3, f6, f49, f34, f0, f39, f54, f53, f14, f5, f51, f42, f17, f31, f35, f11, f38, f45, f20, f22, f10, f27, f1, f12, f23, f48, f25, f18, f15, f24, f26, f2, f33, f41, f52, f4, f13, f19, f36, f44, f16 in input data\ntraining data did not have the following fields: x7_N\u00e3o, Anos desde \u00faltima promo\u00e7\u00e3o, x3_Ci\u00eancias das natureza, Envolvimento com trabalho, Satisfa\u00e7\u00e3o com emprego, Satisfa\u00e7\u00e3o com a rela\u00e7\u00e3o, x1_Engenharia, x5_Tecnico, x3_Outros, x1_Vendas, x3_Medicina, Pontua\u00e7\u00e3o teste, x0_Misto, Horas de treinamento ultimo ano, x5_Assistente, x5_Gerente, x5_Supervisor, x6_Casado, x0_Escrit\u00f3rio, x0_Cliente, Satisfa\u00e7\u00e3o com o ambiente no emprego atual, x4_F, Bonus de performance, Beneficios, Aumento de salario%, Anos na \u00faltima empresa, Anos na posi\u00e7\u00e3o atual, x2_P\u00f3s-gradu\u00e7\u00e3o, Performance na entrevista, x2_M\u00e9dio completo, x5_Diretor, x6_Divorciado, Idade, x3_Ci\u00eancias humanas, x6_Solteiro, Quantidade de empresas que trabalho, Renda, Anos de experiencia, x5_Vendedo senior, Anos com a mesma ger\u00eancia, Distancia casa-trabalho, x3_Marketing, Horas voluntariado, x2_Superior incompleto, x1_RH, Posicao, x5_Engenheiro, x4_M, x5_Vendedor junior, Estilo de vida, x2_Superior completo, x5_Analista, x3_Faculdade T\u00e9cnica, x2_Superior incompleto - cursando, x7_Sim", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)", "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 568, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 605, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 635, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/scorer.py\", line 91, in __call__\n    y_pred = estimator.predict(X)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 118, in <lambda>\n    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/imblearn/pipeline.py\", line 350, in predict\n    return self.steps[-1][-1].predict(Xt, **predict_params)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/xgboost/sklearn.py\", line 646, in predict\n    ntree_limit=ntree_limit)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/xgboost/core.py\", line 1194, in predict\n    self._validate_features(data)\n  File \"/opt/conda/envs/Python36/lib/python3.6/site-packages/xgboost/core.py\", line 1478, in _validate_features\n    data.feature_names))\nValueError: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54'] ['Idade', 'Pontua\u00e7\u00e3o teste', 'Distancia casa-trabalho', 'Satisfa\u00e7\u00e3o com o ambiente no emprego atual', 'Horas voluntariado', 'Envolvimento com trabalho', 'Posicao', 'Satisfa\u00e7\u00e3o com emprego', 'Renda', 'Bonus de performance', 'Quantidade de empresas que trabalho', 'Aumento de salario%', 'Performance na entrevista', 'Satisfa\u00e7\u00e3o com a rela\u00e7\u00e3o', 'Beneficios', 'Anos de experiencia', 'Horas de treinamento ultimo ano', 'Estilo de vida', 'Anos na \u00faltima empresa', 'Anos na posi\u00e7\u00e3o atual', 'Anos desde \u00faltima promo\u00e7\u00e3o', 'Anos com a mesma ger\u00eancia', 'x0_Cliente', 'x0_Escrit\u00f3rio', 'x0_Misto', 'x1_Engenharia', 'x1_RH', 'x1_Vendas', 'x2_M\u00e9dio completo', 'x2_P\u00f3s-gradu\u00e7\u00e3o', 'x2_Superior completo', 'x2_Superior incompleto', 'x2_Superior incompleto - cursando', 'x3_Ci\u00eancias das natureza', 'x3_Ci\u00eancias humanas', 'x3_Faculdade T\u00e9cnica', 'x3_Marketing', 'x3_Medicina', 'x3_Outros', 'x4_F', 'x4_M', 'x5_Analista', 'x5_Assistente', 'x5_Diretor', 'x5_Engenheiro', 'x5_Gerente', 'x5_Supervisor', 'x5_Tecnico', 'x5_Vendedo senior', 'x5_Vendedor junior', 'x6_Casado', 'x6_Divorciado', 'x6_Solteiro', 'x7_N\u00e3o', 'x7_Sim']\nexpected f43, f32, f46, f50, f28, f37, f30, f40, f7, f21, f29, f47, f9, f8, f3, f6, f49, f34, f0, f39, f54, f53, f14, f5, f51, f42, f17, f31, f35, f11, f38, f45, f20, f22, f10, f27, f1, f12, f23, f48, f25, f18, f15, f24, f26, f2, f33, f41, f52, f4, f13, f19, f36, f44, f16 in input data\ntraining data did not have the following fields: x7_N\u00e3o, Anos desde \u00faltima promo\u00e7\u00e3o, x3_Ci\u00eancias das natureza, Envolvimento com trabalho, Satisfa\u00e7\u00e3o com emprego, Satisfa\u00e7\u00e3o com a rela\u00e7\u00e3o, x1_Engenharia, x5_Tecnico, x3_Outros, x1_Vendas, x3_Medicina, Pontua\u00e7\u00e3o teste, x0_Misto, Horas de treinamento ultimo ano, x5_Assistente, x5_Gerente, x5_Supervisor, x6_Casado, x0_Escrit\u00f3rio, x0_Cliente, Satisfa\u00e7\u00e3o com o ambiente no emprego atual, x4_F, Bonus de performance, Beneficios, Aumento de salario%, Anos na \u00faltima empresa, Anos na posi\u00e7\u00e3o atual, x2_P\u00f3s-gradu\u00e7\u00e3o, Performance na entrevista, x2_M\u00e9dio completo, x5_Diretor, x6_Divorciado, Idade, x3_Ci\u00eancias humanas, x6_Solteiro, Quantidade de empresas que trabalho, Renda, Anos de experiencia, x5_Vendedo senior, Anos com a mesma ger\u00eancia, Distancia casa-trabalho, x3_Marketing, Horas voluntariado, x2_Superior incompleto, x1_RH, Posicao, x5_Engenheiro, x4_M, x5_Vendedor junior, Estilo de vida, x2_Superior completo, x5_Analista, x3_Faculdade T\u00e9cnica, x2_Superior incompleto - cursando, x7_Sim\n\"\"\"", "\nThe above exception was the direct cause of the following exception:\n", "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m<ipython-input-9-a7ebe4683be6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Tune Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Fit grid_mse to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrid_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54'] ['Idade', 'Pontua\u00e7\u00e3o teste', 'Distancia casa-trabalho', 'Satisfa\u00e7\u00e3o com o ambiente no emprego atual', 'Horas voluntariado', 'Envolvimento com trabalho', 'Posicao', 'Satisfa\u00e7\u00e3o com emprego', 'Renda', 'Bonus de performance', 'Quantidade de empresas que trabalho', 'Aumento de salario%', 'Performance na entrevista', 'Satisfa\u00e7\u00e3o com a rela\u00e7\u00e3o', 'Beneficios', 'Anos de experiencia', 'Horas de treinamento ultimo ano', 'Estilo de vida', 'Anos na \u00faltima empresa', 'Anos na posi\u00e7\u00e3o atual', 'Anos desde \u00faltima promo\u00e7\u00e3o', 'Anos com a mesma ger\u00eancia', 'x0_Cliente', 'x0_Escrit\u00f3rio', 'x0_Misto', 'x1_Engenharia', 'x1_RH', 'x1_Vendas', 'x2_M\u00e9dio completo', 'x2_P\u00f3s-gradu\u00e7\u00e3o', 'x2_Superior completo', 'x2_Superior incompleto', 'x2_Superior incompleto - cursando', 'x3_Ci\u00eancias das natureza', 'x3_Ci\u00eancias humanas', 'x3_Faculdade T\u00e9cnica', 'x3_Marketing', 'x3_Medicina', 'x3_Outros', 'x4_F', 'x4_M', 'x5_Analista', 'x5_Assistente', 'x5_Diretor', 'x5_Engenheiro', 'x5_Gerente', 'x5_Supervisor', 'x5_Tecnico', 'x5_Vendedo senior', 'x5_Vendedor junior', 'x6_Casado', 'x6_Divorciado', 'x6_Solteiro', 'x7_N\u00e3o', 'x7_Sim']\nexpected f43, f32, f46, f50, f28, f37, f30, f40, f7, f21, f29, f47, f9, f8, f3, f6, f49, f34, f0, f39, f54, f53, f14, f5, f51, f42, f17, f31, f35, f11, f38, f45, f20, f22, f10, f27, f1, f12, f23, f48, f25, f18, f15, f24, f26, f2, f33, f41, f52, f4, f13, f19, f36, f44, f16 in input data\ntraining data did not have the following fields: x7_N\u00e3o, Anos desde \u00faltima promo\u00e7\u00e3o, x3_Ci\u00eancias das natureza, Envolvimento com trabalho, Satisfa\u00e7\u00e3o com emprego, Satisfa\u00e7\u00e3o com a rela\u00e7\u00e3o, x1_Engenharia, x5_Tecnico, x3_Outros, x1_Vendas, x3_Medicina, Pontua\u00e7\u00e3o teste, x0_Misto, Horas de treinamento ultimo ano, x5_Assistente, x5_Gerente, x5_Supervisor, x6_Casado, x0_Escrit\u00f3rio, x0_Cliente, Satisfa\u00e7\u00e3o com o ambiente no emprego atual, x4_F, Bonus de performance, Beneficios, Aumento de salario%, Anos na \u00faltima empresa, Anos na posi\u00e7\u00e3o atual, x2_P\u00f3s-gradu\u00e7\u00e3o, Performance na entrevista, x2_M\u00e9dio completo, x5_Diretor, x6_Divorciado, Idade, x3_Ci\u00eancias humanas, x6_Solteiro, Quantidade de empresas que trabalho, Renda, Anos de experiencia, x5_Vendedo senior, Anos com a mesma ger\u00eancia, Distancia casa-trabalho, x3_Marketing, Horas voluntariado, x2_Superior incompleto, x1_RH, Posicao, x5_Engenheiro, x4_M, x5_Vendedor junior, Estilo de vida, x2_Superior completo, x5_Analista, x3_Faculdade T\u00e9cnica, x2_Superior incompleto - cursando, x7_Sim"]}]}, {"metadata": {}, "cell_type": "code", "source": "# Print scores\n# Print the best parameters and lowest RMSE\nprint(\"\\nBest parameters found: \", grid_acc.best_params_)\nprint(\"\\nHighest average balanced accuracy found: %.4f\" % grid_acc.best_score_)\n\nprint('\\nBest Estimator: \\n', grid_acc.best_estimator_)\n\nprint(' \\nBest test score: %f' % (grid_acc.score(X_test, y_test)))\n\n#Print scores\nprint('\\nTrain score: %f' % grid_acc.score(X_train, y_train))\nprint('Test  score: %f\\n' % grid_acc.score(X_test, y_test))\n\ny_pred = grid_acc.predict(X_test)\nba = balanced_accuracy_score(y_test, y_pred)\ncm = confusion_matrix(y_test, y_pred, labels=['N\u00e3o', 'Sim'])\nac = cm[0,0]/(cm[0,0]+cm[0,1])\nsp = cm[1,1]/(cm[1,1]+cm[1,0])\nauc = roc_auc_score(y_test=='N\u00e3o', y_pred=='N\u00e3o')\n\nprint('\\nBalanced Accuracy : %.4f' % ba)\nprint('AUC               : %.4f' % auc)\nprint('Accuracy          : %.4f' % ac)\nprint('Specificity       : %.4f\\n' % sp)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Encapsulando uma Pipeline personalizada no Watson Machine Learning"}, {"metadata": {}, "cell_type": "code", "source": "#!pip install watson_machine_learning_client --upgrade\n#!pip install joblib --upgrade\n!pip install imbalanced-learn==0.4.3 --upgrade\n!pip install scikit-learn==0.20.1 --upgrade", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "Requirement already up-to-date: imbalanced-learn==0.4.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.4.3)\nRequirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from imbalanced-learn==0.4.3) (0.20.1)\nRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from imbalanced-learn==0.4.3) (1.15.4)\nRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from imbalanced-learn==0.4.3) (1.2.0)\nRequirement already up-to-date: scikit-learn==0.20.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.20.1)\nRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn==0.20.1) (1.2.0)\nRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn==0.20.1) (1.15.4)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import xgboost              as xgb\n\nfrom imblearn.over_sampling   import SMOTE\nfrom imblearn.under_sampling  import RandomUnderSampler\nfrom imblearn.pipeline        import Pipeline", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Assamble Best Model Pipeline\npipeline = Pipeline(steps=[('SMOTE', SMOTE(sampling_strategy=0.3)),\n                           ('under', RandomUnderSampler(random_state=555, sampling_strategy=0.7)),\n                           ('model', xgb.XGBClassifier(objective='binary:logistic',\n                                                       colsample_bytree=0.055, learning_rate=0.6,\n                                                       max_depth=1, n_estimators=150, reg_alpha=0.25))\n                          ])", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Fit Pipeline\npipeline.fit(X_train, y_train)", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "Pipeline(memory=None,\n     steps=[('SMOTE', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n   out_step='deprecated', random_state=None, ratio=None,\n   sampling_strategy=0.3, svm_estimator='deprecated')), ('under', RandomUnderSampler(random_state=555, ratio=None, replacement=False,\n          return...g_alpha=0.25,\n       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n       subsample=1))])"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Estabelecendo conex\u00e3o entre o cliente Python do WML e a sua inst\u00e2ncia do servi\u00e7o na nuvem"}, {"metadata": {}, "cell_type": "code", "source": "# Biblioteca Python com implementa\u00e7\u00e3o de um cliente HTTP para a API do WML\nfrom watson_machine_learning_client import WatsonMachineLearningAPIClient", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "2020-08-27 20:43:28,284 - watson_machine_learning_client.wml_client_error - WARNING - Deployment creation failed. Error: 400. {\"trace\":\"-1iz0y28oegmas\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"The xgboost version 0.80 is not supported with scikit-learn version 0.20 . Expected scikit-learn version here is 0.19 . Retry deployment after saving model with expected scikit-learn version.\"}]}\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "As pr\u00f3ximas c\u00e9lulas ir\u00e3o realizar o deploy da pipeline declarada neste notebook no WML. S\u00f3 prossiga se voc\u00ea j\u00e1 est\u00e1 satisfeito com seu modelo e acha que j\u00e1 \u00e9 a hora de fazer o deploy da sua solu\u00e7\u00e3o.\n\nCole as credenciais de sua inst\u00e2ncia do Watson Machine Learning na vari\u00e1vel na c\u00e9lula abaixo.\n\n\u00c9 importante que a vari\u00e1vel que cont\u00e9m os valores tenha o nome de ``wml_credentials`` para que as pr\u00f3ximas c\u00e9lulas deste notebook executem corretamente."}, {"metadata": {}, "cell_type": "code", "source": "wml_credentials = {\n    \"apikey\": \"UcKj40CKGjKuynWWqaQQM9R8k7mNw-1UW6FAEZ5RtGSw\",\n    \"iam_apikey_description\": \"Auto-generated for key d7837118-bdd4-4b23-9b87-f6752bb14446\",\n    \"iam_apikey_name\": \"wdp-writer\",\n    \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n    \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/47c20058f2c9403d8fdd36abe258ae75::serviceid:ServiceId-68885698-5eef-403f-a93d-51812538b1f2\",\n    \"instance_id\": \"c617f0af-1f55-43c1-a23d-608de97d9765\",\n    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n}", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Instanciando um objeto cliente do Watson Machine Learning a partir das credenciais fornecidas\n\nclientWML = WatsonMachineLearningAPIClient(wml_credentials)", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Extraindo detalhes da sua inst\u00e2ncia do Watson Machine Learning\nimport json\ninstance_details = clientWML.service_instance.get_details()\nprint(json.dumps(instance_details, indent=4))", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "{\n    \"entity\": {\n        \"source\": \"Bluemix\",\n        \"published_models\": {\n            \"url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/c617f0af-1f55-43c1-a23d-608de97d9765/published_models\"\n        },\n        \"usage\": {\n            \"capacity_units\": {\n                \"current\": 0,\n                \"limit\": 180000000\n            },\n            \"computation_time\": {\n                \"current\": 0,\n                \"limit\": 180000\n            },\n            \"deployment_count\": {\n                \"current\": 0,\n                \"limit\": 5\n            },\n            \"expiration_date\": \"2020-09-01T00:00:00.000Z\",\n            \"gpu_count_k80\": {\n                \"current\": 0,\n                \"limit\": 8\n            },\n            \"gpu_count_p100\": {\n                \"current\": 0,\n                \"limit\": 0\n            },\n            \"gpu_count_v100\": {\n                \"current\": 0,\n                \"limit\": 0\n            },\n            \"model_count\": {\n                \"current\": 0,\n                \"limit\": 200\n            },\n            \"prediction_count\": {\n                \"current\": 0,\n                \"limit\": 5000\n            }\n        },\n        \"tags\": null,\n        \"plan_id\": \"3f6acf43-ede8-413a-ac69-f8af3bb0cbfe\",\n        \"service_endpoints\": \"public\",\n        \"status\": \"Active\",\n        \"organization_guid\": \"N/A\",\n        \"region\": \"us-south\",\n        \"account\": {\n            \"id\": \"47c20058f2c9403d8fdd36abe258ae75\",\n            \"name\": \"Celso Leite's Account\",\n            \"type\": \"STANDARD\"\n        },\n        \"owner\": {\n            \"beta_user\": false,\n            \"country_code\": \"BRA\",\n            \"email\": \"cpcleite@me.com\",\n            \"ibm_id\": \"550008EED3\",\n            \"user_id\": \"9bb2aec3-8303-4f81-9937-bd437d421fd1\"\n        },\n        \"deployments\": {\n            \"url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/c617f0af-1f55-43c1-a23d-608de97d9765/deployments\"\n        },\n        \"space_guid\": \"N/A\",\n        \"plan\": \"lite\"\n    },\n    \"metadata\": {\n        \"created_at\": \"2020-08-27T16:42:49.303Z\",\n        \"modified_at\": \"2020-08-27T16:42:49.303Z\",\n        \"guid\": \"c617f0af-1f55-43c1-a23d-608de97d9765\",\n        \"url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/c617f0af-1f55-43c1-a23d-608de97d9765\"\n    }\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**ATEN\u00c7\u00c3O!!**\n\nFique atento para os limites de consumo de sua inst\u00e2ncia do Watson Machine Learning!\n\nCaso voc\u00ea expire a camada gr\u00e1tis, n\u00e3o ser\u00e1 poss\u00edvel avaliar seu modelo (pois \u00e9 necess\u00e1ria a realiza\u00e7\u00e3o de algumas chamadas de API que consomem predi\u00e7\u00f5es!)"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Listando todos os artefatos armazenados no seu WML"}, {"metadata": {}, "cell_type": "markdown", "source": "Para listar todos os artefatos armazenados em seu Watson Machine Learning, voc\u00ea pode usar a seguinte fun\u00e7\u00e3o:\n\n    clientWML.repository.list()"}, {"metadata": {}, "cell_type": "code", "source": "# Listando todos os artefatos atualmente armazenados na sua inst\u00e2ncia do WML\n\nclientWML.repository.list()", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "------------------------------------  -----------------------  ------------------------  ---------  --------------\nGUID                                  NAME                     CREATED                   FRAMEWORK  TYPE\nb1ad06e6-41f6-416e-a158-5b2834bc5cb2  my_custom_wml_runtime_1  2020-08-27T20:23:56.476Z  -          python runtime\n------------------------------------  -----------------------  ------------------------  ---------  --------------\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "No plano LITE do Watson Machine Learning s\u00f3 \u00e9 permitido o deploy de um \u00fanico modelo por vez. Se for o caso de voc\u00ea j\u00e1 possuir um modelo online na sua inst\u00e2ncia, voc\u00ea pode apag\u00e1-lo utilizando o m\u00e9todo clientWML.repository.delete():\n\n    artifact_guid = \"359c8951-d2fe-4063-8706-cc06b32d5e0d\"\n    clientWML.repository.delete(artifact_guid)"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Criando uma nova defini\u00e7\u00e3o de pacote Python personalizado no WML"}, {"metadata": {}, "cell_type": "markdown", "source": "O primeiro passo para realizar seu deploy \u00e9 armazenar o c\u00f3digo das transforma\u00e7\u00f5es personalizadas criadas por voc\u00ea.\n\nPara essa etapa precisamos apenas do arquivo .zip do pacote criado (que j\u00e1 possuimos carregado no Kernel!)"}, {"metadata": {}, "cell_type": "code", "source": "# Defini\u00e7\u00e3o de metadados do nosso pacote com as Transforms personalizadas\n#pkg_meta = {\n#    clientWML.runtimes.LibraryMetaNames.NAME: \"my_custom_sklearn_transform_1\",\n#    clientWML.runtimes.LibraryMetaNames.DESCRIPTION: \"A custom sklearn transform\",\n#    clientWML.runtimes.LibraryMetaNames.FILEPATH: \"sklearn_transforms.zip\",  # Note que estamos utilizando o .zip criado anteriormente!\n#    clientWML.runtimes.LibraryMetaNames.VERSION: \"1.0\",\n#    clientWML.runtimes.LibraryMetaNames.PLATFORM: { \"name\": \"python\", \"versions\": [\"3.6\"] }\n#}\n#custom_package_details = clientWML.runtimes.store_library( pkg_meta )\n#custom_package_uid = clientWML.runtimes.get_library_uid( custom_package_details )\n\nartifact_guid = \"b1ad06e6-41f6-416e-a158-5b2834bc5cb2\"\nclientWML.repository.delete(artifact_guid)\n\nprint(\"\\n Lista de artefatos de runtime armazenados no WML:\")\nclientWML.repository.list()", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "\n Lista de artefatos de runtime armazenados no WML:\n----  ----  -------  ---------  ----\nGUID  NAME  CREATED  FRAMEWORK  TYPE\n----  ----  -------  ---------  ----\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Criando uma nova defini\u00e7\u00e3o de runtime Python personalizado no WML\n\nO segundo passo \u00e9 armazenar uma defini\u00e7\u00e3o de runtime Python para utilizar a nossa biblioteca personalizada.\n\nIsso pode ser feito da seguinte forma:"}, {"metadata": {}, "cell_type": "code", "source": "runtime_meta = {\n    clientWML.runtimes.ConfigurationMetaNames.NAME: \"my_custom_wml_runtime_1\",\n    clientWML.runtimes.ConfigurationMetaNames.DESCRIPTION: \"A Python 3.6 runtime\",\n    clientWML.runtimes.ConfigurationMetaNames.PLATFORM: {\n        \"name\": \"python\",\n        \"version\": \"3.6\"\n    },\n    #clientWML.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS: [ custom_package_uid ]\n}\nruntime_details = clientWML.runtimes.store( runtime_meta )\ncustom_runtime_uid = clientWML.runtimes.get_uid( runtime_details )\n\nprint(\"\\n Detalhes do runtime armazenado:\")\nprint(json.dumps(runtime_details, indent=4))", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "\n Detalhes do runtime armazenado:\n{\n    \"entity\": {\n        \"name\": \"my_custom_wml_runtime_1\",\n        \"description\": \"A Python 3.6 runtime\",\n        \"custom_libraries\": [],\n        \"content_url\": \"https://private.us-south.ml.cloud.ibm.com/v4/runtimes/935b20e4-cd2c-45f7-a716-78e6d719312c/content\",\n        \"platform\": {\n            \"name\": \"python\",\n            \"version\": \"3.6\"\n        }\n    },\n    \"metadata\": {\n        \"created_at\": \"2020-08-27T20:43:00.377Z\",\n        \"guid\": \"935b20e4-cd2c-45f7-a716-78e6d719312c\",\n        \"url\": \"https://us-south.ml.cloud.ibm.com/v4/runtimes/935b20e4-cd2c-45f7-a716-78e6d719312c\"\n    }\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Listando todos runtimes armazenados no seu WML:\nclientWML.runtimes.list()", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "------------------------------------  -----------------------  ------------------------  ----------\nGUID                                  NAME                     CREATED                   PLATFORM\n935b20e4-cd2c-45f7-a716-78e6d719312c  my_custom_wml_runtime_1  2020-08-27T20:43:00.377Z  python-3.6\n------------------------------------  -----------------------  ------------------------  ----------\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Criando uma nova defini\u00e7\u00e3o de Pipeline personalizada no WML\n\nFinalmente iremos criar uma defini\u00e7\u00e3o (metadados) para a nossa Pipeline ser hospedada no WML.\n\nDefinimos como par\u00e2metros um nome para o artefato e o ID do runtime criado anteriormente."}, {"metadata": {}, "cell_type": "code", "source": "model_meta = {\n    clientWML.repository.ModelMetaNames.NAME: 'desafio-4-mbtc2020-pipeline-1',\n    clientWML.repository.ModelMetaNames.DESCRIPTION: \"my pipeline for submission\",\n    clientWML.repository.ModelMetaNames.RUNTIME_UID: custom_runtime_uid\n}", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Em seguida chamamos o m\u00e9todo para armazenar a nova defini\u00e7\u00e3o:"}, {"metadata": {}, "cell_type": "code", "source": "# Fun\u00e7\u00e3o para armazenar uma defini\u00e7\u00e3o de Pipeline no WML\nstored_model_details = clientWML.repository.store_model(\n    model=pipeline,  # `my_pipeline` \u00e9 a vari\u00e1vel criada anteriormente e cont\u00e9m nossa Pipeline j\u00e1 treinada :)\n    meta_props=model_meta,  # Metadados definidos na c\u00e9lula anterior\n    training_data=None  # N\u00e3o altere esse par\u00e2metro\n)\n\nprint(\"\\n Lista de artefatos armazenados no WML:\")\nclientWML.repository.list()\n\n# Detalhes do modelo hospedado no Watson Machine Learning\nprint(\"\\n Metadados do modelo armazenado:\")\nprint(json.dumps(stored_model_details, indent=4))", "execution_count": 23, "outputs": [{"output_type": "stream", "text": "\n Lista de artefatos armazenados no WML:\n------------------------------------  -----------------------------  ------------------------  -----------------  --------------\nGUID                                  NAME                           CREATED                   FRAMEWORK          TYPE\nc3d7f95d-c934-4a80-93c9-105f3d4c64e9  desafio-4-mbtc2020-pipeline-1  2020-08-27T20:43:16.855Z  scikit-learn-0.20  model\n935b20e4-cd2c-45f7-a716-78e6d719312c  my_custom_wml_runtime_1        2020-08-27T20:43:00.377Z  -                  python runtime\n------------------------------------  -----------------------------  ------------------------  -----------------  --------------\n\n Metadados do modelo armazenado:\n{\n    \"metadata\": {\n        \"guid\": \"c3d7f95d-c934-4a80-93c9-105f3d4c64e9\",\n        \"url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/c617f0af-1f55-43c1-a23d-608de97d9765/published_models/c3d7f95d-c934-4a80-93c9-105f3d4c64e9\",\n        \"created_at\": \"2020-08-27T20:43:16.855Z\",\n        \"modified_at\": \"2020-08-27T20:43:16.924Z\"\n    },\n    \"entity\": {\n        \"runtime_environment\": \"python-3.6\",\n        \"learning_configuration_url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/c617f0af-1f55-43c1-a23d-608de97d9765/published_models/c3d7f95d-c934-4a80-93c9-105f3d4c64e9/learning_configuration\",\n        \"name\": \"desafio-4-mbtc2020-pipeline-1\",\n        \"description\": \"my pipeline for submission\",\n        \"learning_iterations_url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/c617f0af-1f55-43c1-a23d-608de97d9765/published_models/c3d7f95d-c934-4a80-93c9-105f3d4c64e9/learning_iterations\",\n        \"feedback_url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/c617f0af-1f55-43c1-a23d-608de97d9765/published_models/c3d7f95d-c934-4a80-93c9-105f3d4c64e9/feedback\",\n        \"latest_version\": {\n            \"url\": \"https://us-south.ml.cloud.ibm.com/v3/ml_assets/models/c3d7f95d-c934-4a80-93c9-105f3d4c64e9/versions/cd72350a-4061-4327-a652-f43ef3806ba0\",\n            \"guid\": \"cd72350a-4061-4327-a652-f43ef3806ba0\",\n            \"created_at\": \"2020-08-27T20:43:16.924Z\"\n        },\n        \"model_type\": \"scikit-learn-0.20\",\n        \"deployments\": {\n            \"count\": 0,\n            \"url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/c617f0af-1f55-43c1-a23d-608de97d9765/published_models/c3d7f95d-c934-4a80-93c9-105f3d4c64e9/deployments\"\n        },\n        \"evaluation_metrics_url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/c617f0af-1f55-43c1-a23d-608de97d9765/published_models/c3d7f95d-c934-4a80-93c9-105f3d4c64e9/evaluation_metrics\",\n        \"runtime\": {\n            \"url\": \"https://us-south.ml.cloud.ibm.com/v4/runtimes/935b20e4-cd2c-45f7-a716-78e6d719312c\"\n        }\n    }\n}\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Realizando o deployment do seu modelo para consumo imediato por outras aplica\u00e7\u00f5es"}, {"metadata": {}, "cell_type": "code", "source": "# O deployment do modelo \u00e9 finalmente realizado por meio do m\u00e9todo ``deployments.create()``\n\nmodel_deployment_details = clientWML.deployments.create(\n    artifact_uid=stored_model_details[\"metadata\"][\"guid\"],  # N\u00e3o altere esse par\u00e2metro\n    name=\"desafio-4-mbtc2020-deployment-1\",\n    description=\"Solu\u00e7\u00e3o do desafio 4 - MBTC\",\n    asynchronous=False,  # N\u00e3o altere esse par\u00e2metro\n    deployment_type='online',  # N\u00e3o altere esse par\u00e2metro\n    deployment_format='Core ML',  # N\u00e3o altere esse par\u00e2metro\n    meta_props=model_meta  # N\u00e3o altere esse par\u00e2metro\n)", "execution_count": 24, "outputs": [{"output_type": "stream", "text": "{\"trace\":\"-1iz0y28oegmas\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"The xgboost version 0.80 is not supported with scikit-learn version 0.20 . Expected scikit-learn version here is 0.19 . Retry deployment after saving model with expected scikit-learn version.\"}]}\n\n\n--------------------------\nDeployment creation failed\n--------------------------\n\n\n", "name": "stdout"}, {"output_type": "error", "ename": "WMLClientError", "evalue": "Deployment creation failed. Error: 400. {\"trace\":\"-1iz0y28oegmas\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"The xgboost version 0.80 is not supported with scikit-learn version 0.20 . Expected scikit-learn version here is 0.19 . Retry deployment after saving model with expected scikit-learn version.\"}]}", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)", "\u001b[0;32m<ipython-input-24-d862c7d22d22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdeployment_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'online'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# N\u00e3o altere esse par\u00e2metro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdeployment_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Core ML'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# N\u00e3o altere esse par\u00e2metro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmeta_props\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_meta\u001b[0m  \u001b[0;31m# N\u00e3o altere esse par\u00e2metro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/watson_machine_learning_client/deployments.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, artifact_uid, name, description, asynchronous, deployment_type, deployment_format, meta_props, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0mprint_text_header_h2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mWMLClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Error: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_online\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_uid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mWMLClientError\u001b[0m: Deployment creation failed. Error: 400. {\"trace\":\"-1iz0y28oegmas\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"The xgboost version 0.80 is not supported with scikit-learn version 0.20 . Expected scikit-learn version here is 0.19 . Retry deployment after saving model with expected scikit-learn version.\"}]}"]}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Testando um modelo hospedado no Watson Machine Learning"}, {"metadata": {}, "cell_type": "code", "source": "# Recuperando a URL endpoint do modelo hospedado na c\u00e9lula anterior\n\nmodel_endpoint_url = clientWML.deployments.get_scoring_url(model_deployment_details)\nprint(\"A URL de chamada da sua API \u00e9: {}\".format(model_endpoint_url))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Detalhes do deployment realizado\n\ndeployment_details = clientWML.deployments.get_details(\n    deployment_uid=model_deployment_details[\"metadata\"][\"guid\"]  # esse \u00e9 o ID do seu deployment!\n)\n\nprint(\"Metadados do deployment realizado: \\n\")\nprint(json.dumps(deployment_details, indent=4))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "scoring_payload = {\n    'fields': [\n        \"MATRICULA\", \"NOME\", 'REPROVACOES_DE', 'REPROVACOES_EM', \"REPROVACOES_MF\", \"REPROVACOES_GO\",\n        \"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\",\n        \"INGLES\", \"H_AULA_PRES\", \"TAREFAS_ONLINE\", \"FALTAS\", \n    ],\n    'values': [\n        [\n            513949,\"Marli Qu\u00e9sia de Oliveira\",1,1,1,1,4.3,4.0,3.1,4.9,0,3,4,3,\n        ]\n    ]\n}\n\nprint(\"\\n Payload de dados a ser classificada:\")\nprint(json.dumps(scoring_payload, indent=4))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "result = clientWML.deployments.score(\n    model_endpoint_url,\n    scoring_payload\n)\n\nprint(\"\\n Resultados:\")\nprint(json.dumps(result, indent=4))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\n\n## Parab\u00e9ns! \n\nSe tudo foi executado sem erros, voc\u00ea j\u00e1 tem um classificador baseado em machine learning encapsulado como uma API REST!\n\nPara testar a sua solu\u00e7\u00e3o integrada com um assistente virtual e realizar a submiss\u00e3o, acesse a p\u00e1gina:\n\nhttps://uninassau.maratona.dev\n\nVoc\u00ea ir\u00e1 precisar da endpoint url do seu modelo e das credenciais do WML :)"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}